{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d925e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0   82450  1.314539  0.590643 -0.666593  0.716564  0.301978 -1.125467   \n",
      "1   50554 -0.798672  1.185093  0.904547  0.694584  0.219041 -0.319295   \n",
      "2   55125 -0.391128 -0.245540  1.122074 -1.308725 -0.639891  0.008678   \n",
      "3  116572 -0.060302  1.065093 -0.987421 -0.029567  0.176376 -1.348539   \n",
      "4   90434  1.848433  0.373364  0.269272  3.866438  0.088062  0.970447   \n",
      "\n",
      "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
      "0  0.388881 -0.288390 -0.132137  ... -0.170307 -0.429655 -0.141341 -0.200195   \n",
      "1  0.495236  0.139269 -0.760214  ...  0.202287  0.578699 -0.092245  0.013723   \n",
      "2 -0.701304 -0.027315 -2.628854  ... -0.133485  0.117403 -0.191748 -0.488642   \n",
      "3  0.775644  0.134843 -0.149734  ...  0.355576  0.907570 -0.018454 -0.126269   \n",
      "4 -0.721945  0.235983  0.683491  ...  0.103563  0.620954  0.197077  0.692392   \n",
      "\n",
      "        V25       V26       V27       V28  Amount  Class  \n",
      "0  0.639491  0.399476 -0.034321  0.031692    0.76      0  \n",
      "1 -0.246466 -0.380057 -0.396030 -0.112901    4.18      0  \n",
      "2 -0.309774  0.008100  0.163716  0.239582   15.00      0  \n",
      "3 -0.339923 -0.150285 -0.023634  0.042330   57.00      0  \n",
      "4 -0.206530 -0.021328 -0.019823 -0.042682    0.00      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "energy_df = pd.read_csv(\"creditcardfraud.csv\")\n",
    "\n",
    "print (energy_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aae997",
   "metadata": {},
   "source": [
    "# 2. Preprocess the data by:\n",
    "# ● Dropping the Time column since it is not useful for classification.\n",
    "# ● Scaling the Amount column using a standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14d6a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0  1.314539  0.590643 -0.666593  0.716564  0.301978 -1.125467  0.388881   \n",
      "1 -0.798672  1.185093  0.904547  0.694584  0.219041 -0.319295  0.495236   \n",
      "2 -0.391128 -0.245540  1.122074 -1.308725 -0.639891  0.008678 -0.701304   \n",
      "3 -0.060302  1.065093 -0.987421 -0.029567  0.176376 -1.348539  0.775644   \n",
      "4  1.848433  0.373364  0.269272  3.866438  0.088062  0.970447 -0.721945   \n",
      "\n",
      "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
      "0 -0.288390 -0.132137 -0.597739  ... -0.170307 -0.429655 -0.141341 -0.200195   \n",
      "1  0.139269 -0.760214  0.170547  ...  0.202287  0.578699 -0.092245  0.013723   \n",
      "2 -0.027315 -2.628854  2.051312  ... -0.133485  0.117403 -0.191748 -0.488642   \n",
      "3  0.134843 -0.149734 -1.238598  ...  0.355576  0.907570 -0.018454 -0.126269   \n",
      "4  0.235983  0.683491  1.166335  ...  0.103563  0.620954  0.197077  0.692392   \n",
      "\n",
      "        V25       V26       V27       V28    Amount  Class  \n",
      "0  0.639491  0.399476 -0.034321  0.031692 -0.443051      0  \n",
      "1 -0.246466 -0.380057 -0.396030 -0.112901 -0.427821      0  \n",
      "2 -0.309774  0.008100  0.163716  0.239582 -0.379637      0  \n",
      "3 -0.339923 -0.150285 -0.023634  0.042330 -0.192602      0  \n",
      "4 -0.206530 -0.021328 -0.019823 -0.042682 -0.446435      0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Drop the 'Time' column if it exists\n",
    "if 'Time' in energy_df.columns:\n",
    "    energy_df.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the 'Amount' column if it exists\n",
    "if 'Amount' in energy_df.columns:\n",
    "    energy_df['Amount'] = scaler.fit_transform(energy_df[['Amount']])\n",
    "\n",
    "# Display the first few rows of the preprocessed data\n",
    "print(energy_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b24ba6",
   "metadata": {},
   "source": [
    "# Split the data into training and test sets using a 80:20 split ratio. Use\n",
    "# random_state=42 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "633ff85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (480, 30)\n",
      "Shape of X_test: (120, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = energy_df  # Features\n",
    "# No need to specify a target variable here for splitting\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and test sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c3518",
   "metadata": {},
   "source": [
    "# Train a logistic regression model on the training set using the default\n",
    "# hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a55bdc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming X_train, X_test are defined earlier in the code\n",
    "# Assuming the target variable is the last column of the dataset\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = energy_df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = energy_df.iloc[:, -1]   # Target variable (last column)\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logistic_reg = LogisticRegression()\n",
    "\n",
    "# Train the model on the training set\n",
    "logistic_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c7876",
   "metadata": {},
   "source": [
    "# Evaluate the model's performance on the test set using:\n",
    "# ● Confusion matrix\n",
    "# ● Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca9c9ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[59  3]\n",
      " [ 4 54]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        62\n",
      "           1       0.95      0.93      0.94        58\n",
      "\n",
      "    accuracy                           0.94       120\n",
      "   macro avg       0.94      0.94      0.94       120\n",
      "weighted avg       0.94      0.94      0.94       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = logistic_reg.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb39cb",
   "metadata": {},
   "source": [
    "# Train an SVM model on the training set using the default hyperparameters. Evaluate the model's performance on the test set using the same evaluation metrics as in step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554e0d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (SVM):\n",
      "[[62  0]\n",
      " [ 6 52]]\n",
      "\n",
      "Classification Report (SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        62\n",
      "           1       1.00      0.90      0.95        58\n",
      "\n",
      "    accuracy                           0.95       120\n",
      "   macro avg       0.96      0.95      0.95       120\n",
      "weighted avg       0.95      0.95      0.95       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize SVM model with default hyperparameters\n",
    "svm_model = SVC()\n",
    "\n",
    "# Train the SVM model on the training set\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix for SVM model\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Print the confusion matrix for SVM model\n",
    "print(\"Confusion Matrix (SVM):\")\n",
    "print(conf_matrix_svm)\n",
    "\n",
    "# Compute the classification report for SVM model\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Print the classification report for SVM model\n",
    "print(\"\\nClassification Report (SVM):\")\n",
    "print(class_report_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b35daf",
   "metadata": {},
   "source": [
    "# Tune the hyperparameters of the logistic regression model and the SVM model using grid search cross-validation. Use a range of values for the hyperparameters of your choice. Choose the evaluation metric of your choice (e.g.Accuracy Score) to optimize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03fa6d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\User\\anaconda3\\etc\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.9125            nan 0.92916667        nan 0.94375\n",
      "        nan 0.93333333        nan 0.93541667        nan 0.9375    ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Logistic Regression: {'C': 0.1, 'penalty': 'l2'}\n",
      "Accuracy Score for Logistic Regression: 0.9583333333333334\n",
      "Best hyperparameters for SVM: {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Accuracy Score for SVM: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the hyperparameters grid for logistic regression\n",
    "param_grid_logistic = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logistic_reg = LogisticRegression()\n",
    "\n",
    "# Initialize GridSearchCV for logistic regression\n",
    "grid_search_logistic = GridSearchCV(estimator=logistic_reg, param_grid=param_grid_logistic, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters for logistic regression\n",
    "print(\"Best hyperparameters for Logistic Regression:\", grid_search_logistic.best_params_)\n",
    "\n",
    "# Evaluate the best logistic regression model on the test set\n",
    "best_logistic_reg = grid_search_logistic.best_estimator_\n",
    "y_pred_logistic = best_logistic_reg.predict(X_test)\n",
    "\n",
    "# Print accuracy score for logistic regression\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(\"Accuracy Score for Logistic Regression:\", accuracy_logistic)\n",
    "\n",
    "\n",
    "# Define the hyperparameters grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Initialize SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Initialize GridSearchCV for SVM\n",
    "grid_search_svm = GridSearchCV(estimator=svm_model, param_grid=param_grid_svm, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters for SVM\n",
    "print(\"Best hyperparameters for SVM:\", grid_search_svm.best_params_)\n",
    "\n",
    "# Evaluate the best SVM model on the test set\n",
    "best_svm_model = grid_search_svm.best_estimator_\n",
    "y_pred_svm = best_svm_model.predict(X_test)\n",
    "\n",
    "# Print accuracy score for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy Score for SVM:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f24b79a",
   "metadata": {},
   "source": [
    "# Train the logistic regression model and the SVM model with the optimal hyperparameters on the training set. Evaluate their performance on the test set using the same evaluation metrics as in step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "434de535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Logistic Regression - Optimal):\n",
      "[[61  1]\n",
      " [ 4 54]]\n",
      "\n",
      "Classification Report (Logistic Regression - Optimal):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        62\n",
      "           1       0.98      0.93      0.96        58\n",
      "\n",
      "    accuracy                           0.96       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.96      0.96      0.96       120\n",
      "\n",
      "Confusion Matrix (SVM - Optimal):\n",
      "[[62  0]\n",
      " [ 5 53]]\n",
      "\n",
      "Classification Report (SVM - Optimal):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        62\n",
      "           1       1.00      0.91      0.95        58\n",
      "\n",
      "    accuracy                           0.96       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.96      0.96      0.96       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model with optimal hyperparameters\n",
    "optimal_logistic_reg = LogisticRegression(**grid_search_logistic.best_params_)\n",
    "optimal_logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test set using the optimal logistic regression model\n",
    "y_pred_logistic_optimal = optimal_logistic_reg.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix for the optimal logistic regression model\n",
    "conf_matrix_logistic_optimal = confusion_matrix(y_test, y_pred_logistic_optimal)\n",
    "\n",
    "# Print the confusion matrix for the optimal logistic regression model\n",
    "print(\"Confusion Matrix (Logistic Regression - Optimal):\")\n",
    "print(conf_matrix_logistic_optimal)\n",
    "\n",
    "# Compute the classification report for the optimal logistic regression model\n",
    "class_report_logistic_optimal = classification_report(y_test, y_pred_logistic_optimal)\n",
    "\n",
    "# Print the classification report for the optimal logistic regression model\n",
    "print(\"\\nClassification Report (Logistic Regression - Optimal):\")\n",
    "print(class_report_logistic_optimal)\n",
    "\n",
    "# Train the SVM model with optimal hyperparameters\n",
    "optimal_svm_model = SVC(**grid_search_svm.best_params_)\n",
    "optimal_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test set using the optimal SVM model\n",
    "y_pred_svm_optimal = optimal_svm_model.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix for the optimal SVM model\n",
    "conf_matrix_svm_optimal = confusion_matrix(y_test, y_pred_svm_optimal)\n",
    "\n",
    "# Print the confusion matrix for the optimal SVM model\n",
    "print(\"Confusion Matrix (SVM - Optimal):\")\n",
    "print(conf_matrix_svm_optimal)\n",
    "\n",
    "# Compute the classification report for the optimal SVM model\n",
    "class_report_svm_optimal = classification_report(y_test, y_pred_svm_optimal)\n",
    "\n",
    "# Print the classification report for the optimal SVM model\n",
    "print(\"\\nClassification Report (SVM - Optimal):\")\n",
    "print(class_report_svm_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5401817",
   "metadata": {},
   "source": [
    "# To compare the performance of the logistic regression model and the SVM model, let's analyze the evaluation metrics obtained from steps 4 and 7, which include the confusion matrix and the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c69d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After comparing the evaluation metrics for both models, we can conclude which one performed better based on the chosen evaluation metrics and the specific characteristics of the dataset.\n",
    "#It's essential to consider the trade-offs between model complexity, computational requirements, and performance when selecting the best model for a given task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4745b9d",
   "metadata": {},
   "source": [
    "# Summarize your findings and conclusions in a brief report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935b275",
   "metadata": {},
   "source": [
    "# Findings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2deadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We conducted an analysis comparing the performance of logistic regression and Support Vector Machine (SVM) models on a given dataset.\n",
    "# Both models were trained and evaluated using the same dataset split into training and test sets.\n",
    "# Evaluation metrics included confusion matrix, classification report, and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bb414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
